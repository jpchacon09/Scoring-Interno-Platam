# Roadmap de Machine Learning con Vertex AI

**Fecha:** 29 de Diciembre de 2025
**Sistema Actual:** PLATAM Scoring V2.0 + HÃ­brido
**Objetivo:** MigraciÃ³n a Machine Learning con Google Vertex AI

---

## ğŸ“‹ Tabla de Contenidos

1. [Estado Actual](#estado-actual)
2. [Â¿QuÃ© Nos Falta?](#quÃ©-nos-falta)
3. [Train/Test Split](#traintest-split-estrategia)
4. [Arquitectura del Sistema ML](#arquitectura-del-sistema-ml)
5. [Triggers y RecÃ¡lculo](#triggers-y-recÃ¡lculo)
6. [Plan de ImplementaciÃ³n](#plan-de-implementaciÃ³n-por-fases)
7. [PreparaciÃ³n de Datos](#preparaciÃ³n-de-datos-detallada)

---

## ğŸ¯ Estado Actual

### Lo Que YA Tenemos âœ…

1. **Scoring V2.0 Robusto**
   - 3 componentes bien calibrados
   - 1,836 clientes calculados
   - Promedio: 724.7 puntos

2. **Sistema HÃ­brido Inteligente**
   - Combina PLATAM + HCPN con pesos dinÃ¡micos
   - Promedio: 746.9 puntos
   - Estabilidad: DesviaciÃ³n estÃ¡ndar 159.4

3. **Datos Estructurados**
   - `hybrid_scores.csv` con 30 columnas
   - `DASHBOARD_SCORING_DINAMICO.csv` con 62 columnas â­
   - Variables categorizadas y limpias

4. **Infraestructura de AnÃ¡lisis**
   - Scripts de cÃ¡lculo automatizados
   - Visualizaciones profesionales
   - DocumentaciÃ³n completa

### Ventaja Competitiva

Ya tenemos **scores de referencia** (V2.0 y HÃ­brido) que podemos usar como:
- **Target labels** para entrenamiento supervisado
- **Baseline** para comparar performance del ML
- **Guardrail** en producciÃ³n (nunca 100% ML)

---

## ğŸ”§ Â¿QuÃ© Nos Falta?

### 1. Datos de Default Reales (CRÃTICO) âš ï¸

**Problema:** NO tenemos variable de default histÃ³rica

**Lo que necesitamos:**
```python
# Columna que identifique clientes que cayeron en default
df['default_flag'] = 0 o 1

Ejemplos:
- Cliente A: 5 pagos a tiempo â†’ default_flag = 0
- Cliente B: 3 pagos + 1 incumplimiento >90d â†’ default_flag = 1
```

**DefiniciÃ³n de Default** (sugerida):
- Mora >90 dÃ­as consecutivos
- Cargo a pÃ©rdidas
- Cuenta enviada a cobranza
- Score de castigo

**AcciÃ³n Inmediata:**
1. Revisar base de datos histÃ³rica
2. Identificar clientes con incumplimientos severos
3. Crear columna `default_flag` en datos
4. Validar con equipo de cobranza/riesgo

### 2. Datos Temporales para ValidaciÃ³n

**Problema:** Necesitamos datos histÃ³ricos con fechas

**Lo que necesitamos:**
- Snapshot de scores en diferentes momentos
- Comportamiento post-score (Â¿el cliente pagÃ³? Â¿incumpliÃ³?)
- MÃ­nimo 6-12 meses de historial

**Ejemplo:**
```
Cliente  | Score_Enero | Score_Junio | Default_Flag (Julio-Dic)
---------|-------------|-------------|-------------------------
123      | 750         | 720         | 0 (pagÃ³ normal)
456      | 650         | 580         | 1 (incumpliÃ³ en Agosto)
```

### 3. Feature Engineering

**Lo que tenemos:**
- Variables bÃ¡sicas (DPD, pagos, utilization)

**Lo que necesitamos agregar:**
- Features de tendencia (DPD Ãºltimo mes vs hace 6 meses)
- Features de estacionalidad (mes del aÃ±o, dÃ­a del pago)
- Features de interacciÃ³n (utilizaciÃ³n Ã— DPD)
- Features derivadas del HCPN (ratio deuda/ingreso)

### 4. ConfiguraciÃ³n de Vertex AI

**Lo que necesitamos:**
1. Proyecto GCP creado
2. API de Vertex AI habilitada
3. Bucket de GCS para datos
4. Service account con permisos
5. CrÃ©ditos GCP asignados

### 5. Pipeline de ML

**Lo que necesitamos construir:**
1. Script de preparaciÃ³n de datos
2. Script de entrenamiento
3. Script de evaluaciÃ³n
4. Script de deployment
5. Script de monitoreo

---

## ğŸ“Š Train/Test Split - Estrategia

### Â¿Por QuÃ© SÃ Dividir?

**Respuesta:** SÃ, SIEMPRE dividir en train/test para:
- Validar que el modelo generaliza
- Evitar overfitting
- Estimar performance real en producciÃ³n
- Comparar mÃºltiples modelos objetivamente

### Estrategia Recomendada: **Temporal + Estratificado**

#### OpciÃ³n 1: Split Temporal (PREFERIDO)

```python
# 80% datos antiguos = TRAIN
# 20% datos recientes = TEST

Ejemplo con 1,836 clientes:
- Train: Enero 2024 - Octubre 2024 (1,469 clientes)
- Test: Noviembre 2024 - Diciembre 2024 (367 clientes)
```

**Ventajas:**
- âœ… Simula producciÃ³n real (entrenar con pasado, predecir futuro)
- âœ… Evita data leakage
- âœ… Refleja cambios de comportamiento temporal

**Desventajas:**
- âš ï¸ Requiere datos con fecha de snapshot
- âš ï¸ Test set puede tener distribuciÃ³n diferente

#### OpciÃ³n 2: Split Estratificado por Rating (ALTERNATIVA)

```python
from sklearn.model_selection import StratifiedShuffleSplit

# Dividir manteniendo proporciÃ³n de ratings
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)

for train_idx, test_idx in split.split(X, y=df['platam_rating']):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]
```

**Ventajas:**
- âœ… FÃ¡cil de implementar
- âœ… Garantiza distribuciÃ³n similar en train/test
- âœ… No requiere datos temporales

**Desventajas:**
- âš ï¸ No simula flujo temporal real
- âš ï¸ Puede haber data leakage si clientes aparecen mÃºltiples veces

#### OpciÃ³n 3: Split por Default (IDEAL si tenemos defaults)

```python
from sklearn.model_selection import StratifiedShuffleSplit

# Estratificar por default_flag (0 o 1)
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)

for train_idx, test_idx in split.split(X, y=df['default_flag']):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

# Asegurar que ambos sets tengan defaults y no-defaults
```

**Ventajas:**
- âœ… Balanceo correcto de clases
- âœ… Evita sets sin defaults (crÃ­tico para mÃ©tricas)

### DistribuciÃ³n Recomendada

| Set | % Datos | Uso | Clientes (de 1,836) |
|-----|---------|-----|---------------------|
| **Train** | 70% | Entrenar modelo | 1,285 |
| **Validation** | 15% | Ajustar hiperparÃ¡metros | 275 |
| **Test** | 15% | Evaluar final | 276 |

**Alternativa para datasets pequeÃ±os:**

| Set | % Datos | Uso | Clientes (de 1,836) |
|-----|---------|-----|---------------------|
| **Train** | 80% | Entrenar modelo | 1,469 |
| **Test** | 20% | Evaluar final | 367 |

Usar **K-Fold Cross-Validation** (k=5) en train para hiperparÃ¡metros.

---

## ğŸ—ï¸ Arquitectura del Sistema ML

### Diagrama de Flujo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. INGESTA DE DATOS                                             â”‚
â”‚    â€¢ BigQuery / Cloud SQL â†’ Raw Data                            â”‚
â”‚    â€¢ Datos de pagos, cupos, HCPN                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. FEATURE ENGINEERING                                          â”‚
â”‚    â€¢ Limpieza de datos                                          â”‚
â”‚    â€¢ ImputaciÃ³n de missing values                               â”‚
â”‚    â€¢ NormalizaciÃ³n (StandardScaler)                             â”‚
â”‚    â€¢ One-hot encoding de categÃ³ricas                            â”‚
â”‚    â€¢ Features derivadas (ratios, tendencias)                    â”‚
â”‚    â€¢ Feature store (Vertex AI Feature Store)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ENTRENAMIENTO (Vertex AI Training)                           â”‚
â”‚    â€¢ Train/Validation/Test split                                â”‚
â”‚    â€¢ MÃºltiples modelos:                                         â”‚
â”‚      - XGBoost (recomendado para tabular)                       â”‚
â”‚      - Random Forest                                            â”‚
â”‚      - LightGBM                                                 â”‚
â”‚      - Logistic Regression (baseline)                           â”‚
â”‚    â€¢ Hyperparameter tuning (Vertex AI Hyperparameter Tuning)    â”‚
â”‚    â€¢ Cross-validation                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. EVALUACIÃ“N                                                   â”‚
â”‚    â€¢ MÃ©tricas de clasificaciÃ³n:                                 â”‚
â”‚      - AUC-ROC                                                  â”‚
â”‚      - Precision, Recall, F1                                    â”‚
â”‚      - Confusion Matrix                                         â”‚
â”‚    â€¢ MÃ©tricas de regresiÃ³n (si predicciÃ³n de score):            â”‚
â”‚      - MAE, RMSE, RÂ²                                            â”‚
â”‚    â€¢ ComparaciÃ³n con baseline (HÃ­brido)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. DEPLOYMENT (Vertex AI Endpoints)                             â”‚
â”‚    â€¢ Registro del modelo en Model Registry                      â”‚
â”‚    â€¢ Deployment a endpoint                                      â”‚
â”‚    â€¢ A/B testing (20% ML, 80% HÃ­brido)                          â”‚
â”‚    â€¢ Monitoring de predicciones                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. SCORING HÃBRIDO EN PRODUCCIÃ“N                                â”‚
â”‚    â€¢ Score_Final = (HÃ­brido Ã— 0.7) + (ML Ã— 0.3)                 â”‚
â”‚    â€¢ Explicabilidad (SHAP values)                               â”‚
â”‚    â€¢ Guardrails (mÃ­n/mÃ¡x score)                                 â”‚
â”‚    â€¢ Logging de predicciones                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. MONITOREO Y RE-ENTRENAMIENTO                                 â”‚
â”‚    â€¢ Model monitoring (data drift, prediction drift)            â”‚
â”‚    â€¢ Re-entrenamiento mensual automÃ¡tico                        â”‚
â”‚    â€¢ Champion/Challenger comparison                             â”‚
â”‚    â€¢ Alertas de degradaciÃ³n de performance                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stack TecnolÃ³gico

| Componente | TecnologÃ­a | Uso |
|------------|------------|-----|
| **OrquestaciÃ³n** | Vertex AI Pipelines | Automatizar flujo completo |
| **Feature Store** | Vertex AI Feature Store | Almacenar features procesadas |
| **Training** | Vertex AI Training | Entrenar modelos a escala |
| **Hyperparameter Tuning** | Vertex AI Vizier | Optimizar hiperparÃ¡metros |
| **Model Registry** | Vertex AI Model Registry | Versionar modelos |
| **Deployment** | Vertex AI Endpoints | Servir predicciones en tiempo real |
| **Monitoring** | Vertex AI Model Monitoring | Detectar drift y degradaciÃ³n |
| **Batch Prediction** | Vertex AI Batch Prediction | Scoring batch mensual |
| **Storage** | Google Cloud Storage (GCS) | Datos, modelos, logs |
| **Data Warehouse** | BigQuery | Datos estructurados |
| **Notebooks** | Vertex AI Workbench | ExperimentaciÃ³n y desarrollo |

---

## âš™ï¸ Triggers y RecÃ¡lculo

### Triggers de Re-Scoring Individual

Recalcular score de un cliente cuando:

| Evento | Trigger | CÃ¡lculo | Latencia |
|--------|---------|---------|----------|
| **Pago realizado** | POST /payment | V2.0 + HÃ­brido + ML | Real-time (<1s) |
| **Nuevo crÃ©dito** | POST /loan | V2.0 + HÃ­brido + ML | Real-time (<1s) |
| **Incumplimiento** | POST /default | V2.0 + HÃ­brido + ML | Real-time (<1s) |
| **ActualizaciÃ³n HCPN** | Webhook | HÃ­brido + ML | Near real-time (<5s) |
| **Cambio manual** | Admin panel | V2.0 + HÃ­brido + ML | Real-time (<1s) |

**ImplementaciÃ³n:**

```python
# API endpoint ejemplo
@app.post("/api/v1/payment")
async def create_payment(payment: Payment):
    # 1. Registrar pago en DB
    db.payments.insert(payment)

    # 2. Trigger re-scoring
    client_id = payment.client_id

    # Calcular scores (paralelo)
    platam_score = await calculate_platam_v2(client_id)
    hcpn_score = await get_hcpn_score(client_id)
    hybrid_score = calculate_hybrid(platam_score, hcpn_score, ...)

    # PredicciÃ³n ML (Vertex AI endpoint)
    ml_score = await vertex_ai_predict(client_id, features)

    # Score final combinado
    final_score = (hybrid_score * 0.7) + (ml_score * 0.3)

    # 3. Guardar scores
    db.scores.update(client_id, {
        'platam_score': platam_score,
        'hybrid_score': hybrid_score,
        'ml_score': ml_score,
        'final_score': final_score,
        'updated_at': now()
    })

    # 4. Retornar respuesta
    return {"score": final_score, "rating": get_rating(final_score)}
```

### Triggers de Re-Entrenamiento del Modelo ML

Re-entrenar modelo completo cuando:

| Trigger | Frecuencia | MÃ©todo | ValidaciÃ³n |
|---------|------------|--------|------------|
| **Mensual automÃ¡tico** | Cada 1er dÃ­a del mes | Vertex AI Pipeline | Champion vs Challenger |
| **Data drift detectado** | Alerta automÃ¡tica | On-demand | Comparar distribuciones |
| **Performance degradaciÃ³n** | AUC cae >5% | On-demand | Backtesting |
| **Nuevas features** | Manual | On-demand | A/B test |
| **Cambio de negocio** | Manual | On-demand | ValidaciÃ³n stakeholders |

**ImplementaciÃ³n:**

```python
# Cloud Function que se ejecuta mensualmente
@functions_framework.cloud_event
def retrain_model(cloud_event):
    """
    Trigger: Cloud Scheduler (1er dÃ­a del mes, 2:00 AM)
    """

    # 1. Extraer datos del Ãºltimo mes
    df_new = query_bigquery(f"""
        SELECT * FROM scores
        WHERE calculation_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 1 MONTH)
    """)

    # 2. Verificar data drift
    drift_detected = check_data_drift(df_new, df_baseline)

    if drift_detected:
        send_alert("âš ï¸ Data drift detectado - Re-entrenamiento necesario")

    # 3. Preparar datos
    X_train, X_test, y_train, y_test = prepare_data(df_new)

    # 4. Entrenar modelo (Vertex AI Pipeline)
    pipeline_job = vertex_ai.PipelineJob(
        display_name="monthly-retrain",
        template_path="gs://bucket/pipeline.json",
        parameter_values={
            "train_data": "gs://bucket/train.csv",
            "test_data": "gs://bucket/test.csv",
            "model_type": "xgboost"
        }
    )

    pipeline_job.run()

    # 5. Evaluar nuevo modelo (Challenger)
    challenger_metrics = evaluate_model(new_model, X_test, y_test)
    champion_metrics = get_production_model_metrics()

    # 6. Comparar Champion vs Challenger
    if challenger_metrics['auc'] > champion_metrics['auc']:
        # Promover Challenger a Champion
        deploy_model(new_model, endpoint="production")
        send_notification("âœ… Nuevo modelo desplegado - AUC mejorÃ³")
    else:
        send_notification("âš ï¸ Nuevo modelo NO superÃ³ al actual")
```

### Batch Re-Scoring (Mensual)

Recalcular todos los scores una vez al mes:

```python
# Cloud Function programada mensualmente
@functions_framework.cloud_event
def batch_rescoring(cloud_event):
    """
    Trigger: Cloud Scheduler (Ãºltimo domingo del mes, 3:00 AM)
    """

    # 1. Obtener todos los clientes activos
    clients = db.clients.find({"status": "active"})

    # 2. Preparar datos para batch prediction
    features_df = prepare_features_batch(clients)

    # 3. Batch prediction con Vertex AI
    batch_job = vertex_ai.BatchPredictionJob.create(
        job_display_name="monthly-batch-scoring",
        model_name="projects/PROJECT/locations/REGION/models/MODEL_ID",
        instances_format="csv",
        gcs_source="gs://bucket/features_batch.csv",
        gcs_destination_prefix="gs://bucket/predictions/",
        machine_type="n1-standard-4"
    )

    batch_job.wait()

    # 4. Cargar predicciones
    ml_scores = load_predictions("gs://bucket/predictions/")

    # 5. Calcular scores hÃ­bridos
    for client_id, ml_score in ml_scores.items():
        platam_score = get_platam_score(client_id)
        hcpn_score = get_hcpn_score(client_id)
        hybrid_score = calculate_hybrid(platam_score, hcpn_score, ...)

        final_score = (hybrid_score * 0.7) + (ml_score * 0.3)

        # Guardar
        db.scores.update(client_id, {
            'ml_score': ml_score,
            'hybrid_score': hybrid_score,
            'final_score': final_score,
            'last_batch_update': now()
        })

    send_notification(f"âœ… Batch re-scoring completado: {len(ml_scores)} clientes")
```

---

## ğŸ“… Plan de ImplementaciÃ³n por Fases

### FASE 0: PreparaciÃ³n de Datos (1-2 semanas)

**Objetivos:**
- âœ… Obtener datos de default histÃ³ricos
- âœ… Crear variable target (`default_flag`)
- âœ… Limpiar y validar datos
- âœ… Feature engineering inicial

**Tareas:**
1. ReuniÃ³n con equipo de cobranza/riesgo para definir "default"
2. Query a base de datos histÃ³rica
3. Crear columna `default_flag` en `DASHBOARD_SCORING_DINAMICO.csv`
4. AnÃ¡lisis exploratorio de defaults:
   - Â¿CuÃ¡ntos clientes cayeron en default?
   - Â¿CuÃ¡l es el balance de clases? (default vs no-default)
   - Â¿Hay suficientes defaults para ML? (mÃ­nimo 50-100)
5. Crear features adicionales:
   - Tendencias temporales (DPD Ãºltimo mes - DPD hace 6 meses)
   - Ratios financieros (deuda/ingreso, cuota/ingreso)
   - Features de HCPN (crÃ©ditos activos, mora externa)

**Entregables:**
- `ml_training_data.csv` con variable `default_flag`
- Notebook de EDA (Exploratory Data Analysis)
- Reporte de calidad de datos

### FASE 1: Setup de Infraestructura GCP (1 semana)

**Objetivos:**
- âœ… Configurar proyecto GCP
- âœ… Habilitar APIs necesarias
- âœ… Crear buckets y datasets

**Tareas:**
1. Crear proyecto GCP (o usar existente)
2. Habilitar APIs:
   ```bash
   gcloud services enable aiplatform.googleapis.com
   gcloud services enable storage-api.googleapis.com
   gcloud services enable bigquery.googleapis.com
   ```
3. Crear bucket de GCS:
   ```bash
   gsutil mb -l us-central1 gs://platam-ml-scoring/
   ```
4. Crear dataset de BigQuery:
   ```bash
   bq mk --dataset --location=US platam_scoring
   ```
5. Configurar service account con permisos
6. Subir datos a GCS y BigQuery

**Entregables:**
- Proyecto GCP configurado
- Buckets y datasets creados
- Datos subidos y accesibles

### FASE 2: Baseline ML (2-3 semanas)

**Objetivos:**
- âœ… Entrenar primer modelo baseline
- âœ… Evaluar performance vs HÃ­brido
- âœ… Establecer mÃ©tricas de Ã©xito

**Tareas:**
1. Train/Test split (80/20, estratificado por default_flag)
2. Entrenar modelos baseline:
   - Logistic Regression
   - Random Forest
   - XGBoost
3. Evaluar en test set:
   - AUC-ROC, Precision, Recall, F1
   - Comparar con HÃ­brido como baseline
4. Feature importance analysis
5. Hyperparameter tuning (grid search)
6. Documentar resultados

**CÃ³digo ejemplo:**
```python
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
from sklearn.metrics import roc_auc_score, classification_report

# 1. Cargar datos
df = pd.read_csv('ml_training_data.csv')

# 2. Features y target
feature_cols = ['dpd_promedio', 'pagos_total', 'utilizacion_pct',
                'meses_como_cliente', 'score_platam_v2', 'score_hcpn_normalizado',
                'comp1_payment_performance_pct', 'comp2_payment_plan_pct',
                'comp3_deterioration_velocity_pct', 'hcpn_creditos_activos']

X = df[feature_cols]
y = df['default_flag']

# 3. Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# 4. NormalizaciÃ³n
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 5. Entrenar XGBoost
model = XGBClassifier(
    max_depth=6,
    learning_rate=0.1,
    n_estimators=100,
    random_state=42
)

model.fit(X_train_scaled, y_train)

# 6. Evaluar
y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
auc = roc_auc_score(y_test, y_pred_proba)

print(f"AUC-ROC: {auc:.3f}")
print(classification_report(y_test, model.predict(X_test_scaled)))

# 7. Feature importance
import matplotlib.pyplot as plt

feature_importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

plt.barh(feature_importance['feature'], feature_importance['importance'])
plt.title('Feature Importance')
plt.savefig('feature_importance.png')
```

**Entregables:**
- Modelos baseline entrenados
- Reporte de evaluaciÃ³n (AUC, mÃ©tricas)
- Feature importance charts

### FASE 3: MigraciÃ³n a Vertex AI (2-3 semanas)

**Objetivos:**
- âœ… Migrar pipeline a Vertex AI
- âœ… Automatizar entrenamiento
- âœ… Deploy modelo a endpoint

**Tareas:**
1. Crear pipeline de Vertex AI (Kubeflow Pipelines)
2. Configurar Vertex AI Training job
3. Hyperparameter tuning con Vizier
4. Registrar modelo en Model Registry
5. Deploy a Vertex AI Endpoint
6. Probar predicciones en tiempo real

**Entregables:**
- Pipeline automatizado
- Modelo desplegado en endpoint
- API de predicciÃ³n funcionando

### FASE 4: IntegraciÃ³n con Sistema HÃ­brido (1-2 semanas)

**Objetivos:**
- âœ… Combinar ML con HÃ­brido
- âœ… Implementar triggers
- âœ… A/B testing

**Tareas:**
1. Modificar API para llamar endpoint de Vertex AI
2. Implementar scoring combinado: (HÃ­brido Ã— 0.7) + (ML Ã— 0.3)
3. Configurar triggers de re-scoring individual
4. A/B testing: 20% ML, 80% HÃ­brido
5. Monitoreo de latencia y errores

**Entregables:**
- API actualizada con ML
- Sistema de triggers funcionando
- Dashboard de A/B testing

### FASE 5: Monitoreo y OptimizaciÃ³n (Continuo)

**Objetivos:**
- âœ… Monitorear performance
- âœ… Re-entrenar mensualmente
- âœ… Optimizar features

**Tareas:**
1. Configurar Vertex AI Model Monitoring
2. Alertas de data drift y prediction drift
3. Pipeline de re-entrenamiento mensual
4. IteraciÃ³n de features
5. Ajuste de pesos HÃ­brido/ML

**Entregables:**
- Sistema de monitoreo activo
- Re-entrenamiento automÃ¡tico configurado

---

## ğŸ§¹ PreparaciÃ³n de Datos Detallada

### 1. Limpieza de Datos

```python
import pandas as pd
import numpy as np

df = pd.read_csv('DASHBOARD_SCORING_DINAMICO.csv')

# 1.1 Eliminar duplicados
df = df.drop_duplicates(subset='cliente_id')

# 1.2 Eliminar columnas irrelevantes
drop_cols = ['nombre', 'email', 'fecha_calculo', 'version_scoring']
df = df.drop(columns=drop_cols)

# 1.3 Manejar missing values
# OpciÃ³n A: Imputar con mediana (variables numÃ©ricas)
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='median')
numeric_cols = df.select_dtypes(include=[np.number]).columns
df[numeric_cols] = imputer.fit_transform(df[numeric_cols])

# OpciÃ³n B: Imputar con moda (variables categÃ³ricas)
cat_cols = df.select_dtypes(include=['object']).columns
for col in cat_cols:
    df[col].fillna(df[col].mode()[0], inplace=True)

# 1.4 Detectar outliers (opcional)
from scipy import stats

# Z-score method
z_scores = np.abs(stats.zscore(df[numeric_cols]))
df_no_outliers = df[(z_scores < 3).all(axis=1)]

print(f"Clientes eliminados por outliers: {len(df) - len(df_no_outliers)}")
```

### 2. Feature Engineering

```python
# 2.1 Features de tendencia
df['dpd_trend'] = df['dpd_max'] - df['dpd_promedio']
df['score_trend'] = df['score_hibrido'] - df['score_platam_v2']

# 2.2 Features de ratio
df['ratio_cupo_utilizado'] = df['cupo_utilizado'] / (df['cupo_total'] + 1)  # +1 para evitar divisiÃ³n por 0
df['ratio_pagos_mora'] = df['dpd_promedio'] / (df['pagos_total'] + 1)

# 2.3 Features categÃ³ricas binarias
df['es_cliente_maduro'] = (df['meses_como_cliente'] >= 12).astype(int)
df['tiene_mora_actual'] = (df['flag_mora_actual'] == True).astype(int)
df['alta_utilizacion'] = (df['utilizacion_pct'] > 80).astype(int)

# 2.4 Interacciones
df['dpd_x_utilizacion'] = df['dpd_promedio'] * df['utilizacion_pct']
df['score_x_pagos'] = df['score_platam_v2'] * df['pagos_total']

# 2.5 Bucketing (discretizaciÃ³n)
df['dpd_bucket'] = pd.cut(df['dpd_promedio'], bins=[0, 5, 15, 30, 60, np.inf], labels=['0-5', '6-15', '16-30', '31-60', '60+'])
df['score_bucket'] = pd.cut(df['score_hibrido'], bins=[0, 500, 700, 850, 1000], labels=['Bajo', 'Medio', 'Alto', 'Excelente'])
```

### 3. NormalizaciÃ³n

```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler

# OpciÃ³n A: StandardScaler (z-score normalization)
scaler = StandardScaler()
numeric_features = ['dpd_promedio', 'pagos_total', 'utilizacion_pct', 'meses_como_cliente']
df[numeric_features] = scaler.fit_transform(df[numeric_features])

# OpciÃ³n B: MinMaxScaler (0-1 scaling)
scaler = MinMaxScaler()
df[numeric_features] = scaler.fit_transform(df[numeric_features])

# Guardar scaler para uso en producciÃ³n
import joblib
joblib.dump(scaler, 'scaler.pkl')
```

### 4. Encoding de CategÃ³ricas

```python
from sklearn.preprocessing import OneHotEncoder, LabelEncoder

# OpciÃ³n A: One-Hot Encoding (para pocas categorÃ­as)
categorical_cols = ['meses_categoria', 'utilizacion_categoria', 'segmento_riesgo_hibrido']

df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

# OpciÃ³n B: Label Encoding (para muchas categorÃ­as o tree-based models)
le = LabelEncoder()
df['meses_categoria_encoded'] = le.fit_transform(df['meses_categoria'])

# OpciÃ³n C: Target Encoding (avanzado)
# Codificar categorÃ­a por promedio de target
for col in categorical_cols:
    target_mean = df.groupby(col)['default_flag'].mean()
    df[f'{col}_target_enc'] = df[col].map(target_mean)
```

### 5. Balanceo de Clases (si hay desbalance)

```python
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler

# Si default_flag estÃ¡ desbalanceado (ej: 5% defaults, 95% no-defaults)

# OpciÃ³n A: SMOTE (Synthetic Minority Over-sampling)
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# OpciÃ³n B: Random Under-sampling
rus = RandomUnderSampler(random_state=42)
X_resampled, y_resampled = rus.fit_resample(X_train, y_train)

# OpciÃ³n C: Usar class_weight en el modelo
model = XGBClassifier(scale_pos_weight=len(y[y==0]) / len(y[y==1]))
```

---

## ğŸš€ Siguiente Paso Inmediato

### ACCIÃ“N REQUERIDA:

**1. Obtener variable de default** âš ï¸

Sin esta variable, NO podemos entrenar modelo supervisado de ML.

**Opciones:**
- **OpciÃ³n A (Ideal):** Consultar base de datos histÃ³rica para clientes que cayeron en default
- **OpciÃ³n B (Workaround):** Usar score actual como proxy de "riesgo" y entrenar modelo de regresiÃ³n para predecir score
- **OpciÃ³n C (Temporal):** Clustering no supervisado para identificar grupos de riesgo

**2. Decidir si empezar ahora o esperar datos**

- **Empezar ahora:** Usar OpciÃ³n B o C, entrenar modelo de regresiÃ³n para predecir score
- **Esperar:** Recolectar datos de default por 3-6 meses, luego entrenar clasificador

---

**Â¿Quieres que empecemos con la implementaciÃ³n?**

Podemos comenzar con:
1. Feature engineering avanzado
2. Modelo de regresiÃ³n (predecir score) como primer MVP
3. Setup de Vertex AI
4. Pipeline bÃ¡sico de entrenamiento

Dime quÃ© prefieres y arrancamos! ğŸš€
